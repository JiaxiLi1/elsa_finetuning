#!/bin/bash
# OwLore mergeæ•°æ®é›†è®­ç»ƒæ¨¡å‹çš„è¯„ä¼°è„šæœ¬
# ç›´æ¥è¯„ä¼°å·²è®­ç»ƒå¥½çš„æ¨¡å‹

echo "ğŸ¯ å¼€å§‹è¯„ä¼°mergeæ•°æ®é›†è®­ç»ƒçš„æ‰€æœ‰æ¨¡å‹"
echo "ğŸ“… å¼€å§‹æ—¶é—´: $(date)"
echo ""

# æ¿€æ´»condaç¯å¢ƒçš„å‡½æ•°
activate_conda() {
    source /home/rtx3090/miniconda3/etc/profile.d/conda.sh
    conda activate $1
    echo "âœ… æ¿€æ´»ç¯å¢ƒ: $1"
}

# æ¿€æ´»è¯„ä¼°ç¯å¢ƒ
activate_conda owlore_eval

# 1. è¯„ä¼° LoRA æ¨¡å‹
echo "============================================================"
echo "ğŸ“Š è¯„ä¼° LoRA æ¨¡å‹"
echo "============================================================"

# æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆæ¨¡å‹æ–‡ä»¶ï¼Œå¦åˆ™ä½¿ç”¨æœ€æ–°checkpoint
if [ -f "output_models/my_finetuned_model_lora/model.safetensors" ]; then
    model_path="output_models/my_finetuned_model_lora"
    echo "ä½¿ç”¨æœ€ç»ˆæ¨¡å‹: $model_path"
elif [ -d "output_models/my_finetuned_model_lora/checkpoint-1739" ]; then
    model_path="output_models/my_finetuned_model_lora/checkpoint-1739"
    echo "ä½¿ç”¨checkpoint: $model_path"
elif [ -d "output_models/my_finetuned_model_lora/checkpoint-60" ]; then
    model_path="output_models/my_finetuned_model_lora/checkpoint-60"
    echo "ä½¿ç”¨checkpoint: $model_path"
else
    echo "âŒ LoRA æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"
    model_path=""
fi

if [ -n "$model_path" ]; then
    python run_owlore_eval.py \
        --model_path "$model_path" \
        --finetune_method lora \
        --adapter_scope all \
        --rank 8 \
        --alpha 16 \
        --sparsity 0.001 \
        --gamma 0.7 \
        --sparse_method svd \
        --sparse_svd_rank 256 \
        --cola_silu true \
        --cola_init false \
        --svd_inverse false \
        --tasks "boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa" \
        --output_path "final_results/LoRA_results" \
        --num_fewshot 5 \
        --batch_size auto
    
    if [ $? -eq 0 ]; then
        echo "âœ… LoRA è¯„ä¼°å®Œæˆ"
    else
        echo "âŒ LoRA è¯„ä¼°å¤±è´¥"
    fi
fi

echo ""
echo "ğŸ˜´ ä¼‘æ¯10ç§’..."
sleep 10

# 2. è¯„ä¼° ELSA_SiLU_True æ¨¡å‹
echo "============================================================"
echo "ğŸ“Š è¯„ä¼° ELSA_SiLU_True æ¨¡å‹"
echo "============================================================"

if [ -d "output_models/my_finetuned_model_elsa/checkpoint-60" ]; then
    python run_owlore_eval.py \
        --model_path "output_models/my_finetuned_model_elsa/checkpoint-60" \
        --finetune_method elsa \
        --adapter_scope all \
        --rank 7 \
        --alpha 14 \
        --sparsity 0.001 \
        --gamma 0.7 \
        --sparse_method svd \
        --sparse_svd_rank 256 \
        --cola_silu true \
        --cola_init false \
        --svd_inverse false \
        --tasks "boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa" \
        --output_path "final_results/ELSA_SiLU_True_results" \
        --num_fewshot 5 \
        --batch_size auto
    
    if [ $? -eq 0 ]; then
        echo "âœ… ELSA_SiLU_True è¯„ä¼°å®Œæˆ"
    else
        echo "âŒ ELSA_SiLU_True è¯„ä¼°å¤±è´¥"
    fi
else
    echo "âŒ ELSA_SiLU_True æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: output_models/my_finetuned_model_elsa/checkpoint-60"
fi

echo ""
echo "ğŸ˜´ ä¼‘æ¯10ç§’..."
sleep 10

# 3. è¯„ä¼° COLA æ¨¡å‹
echo "============================================================"
echo "ğŸ“Š è¯„ä¼° COLA æ¨¡å‹"
echo "============================================================"

if [ -f "output_models/my_finetuned_model_cola/model.safetensors" ]; then
    python run_owlore_eval.py \
        --model_path "output_models/my_finetuned_model_cola" \
        --finetune_method cola \
        --adapter_scope all \
        --rank 8 \
        --alpha 16 \
        --sparsity 0.001 \
        --gamma 0.7 \
        --sparse_method svd \
        --sparse_svd_rank 256 \
        --cola_silu true \
        --cola_init true \
        --svd_inverse false \
        --tasks "boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa" \
        --output_path "final_results/COLA_results" \
        --num_fewshot 5 \
        --batch_size auto
    
    if [ $? -eq 0 ]; then
        echo "âœ… COLA è¯„ä¼°å®Œæˆ"
    else
        echo "âŒ COLA è¯„ä¼°å¤±è´¥"
    fi
else
    echo "âŒ COLA æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: output_models/my_finetuned_model_cola/model.safetensors"
fi

echo ""
echo "ğŸ˜´ ä¼‘æ¯10ç§’..."
sleep 10

# 4. è¯„ä¼° LORO æ¨¡å‹
echo "============================================================"
echo "ğŸ“Š è¯„ä¼° LORO æ¨¡å‹"
echo "============================================================"

if [ -d "output_models/my_finetuned_model/checkpoint-60" ]; then
    python run_owlore_eval.py \
        --model_path "output_models/my_finetuned_model/checkpoint-60" \
        --finetune_method loro \
        --adapter_scope all \
        --rank 8 \
        --alpha 16 \
        --sparsity 0.001 \
        --gamma 0.7 \
        --sparse_method svd \
        --sparse_svd_rank 256 \
        --cola_silu true \
        --cola_init false \
        --svd_inverse false \
        --tasks "boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa" \
        --output_path "final_results/LORO_results" \
        --num_fewshot 5 \
        --batch_size auto
    
    if [ $? -eq 0 ]; then
        echo "âœ… LORO è¯„ä¼°å®Œæˆ"
    else
        echo "âŒ LORO è¯„ä¼°å¤±è´¥"
    fi
else
    echo "âŒ LORO æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: output_models/my_finetuned_model/checkpoint-60"
fi

echo ""
echo "ğŸ‰ æ‰€æœ‰æ¨¡å‹è¯„ä¼°å®Œæˆ!"
echo "ğŸ“… å®Œæˆæ—¶é—´: $(date)"
echo "ğŸ“ æŸ¥çœ‹ç»“æœ:"
echo "  - è¯„ä¼°ç»“æœ: final_results/"
echo ""
echo "ğŸ“Š ç»“æœæ–‡ä»¶:"
ls -la final_results/ 2>/dev/null || echo "final_resultsç›®å½•ä¸å­˜åœ¨"