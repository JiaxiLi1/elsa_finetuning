#!/usr/bin/env python3
"""
ä½¿ç”¨è‡ªå®šä¹‰æ¨¡åž‹åŠ è½½å™¨è¯„ä¼°åŒ…å«è‡ªå®šä¹‰æ¨¡å—çš„æ¨¡åž‹ç¤ºä¾‹

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ lm-eval çš„è‡ªå®šä¹‰æ¨¡åž‹åŠ è½½å™¨æ¥è¯„ä¼°
ä½¿ç”¨ LoRAã€CoLAã€ELSAã€LoRO ç­‰è‡ªå®šä¹‰æ¨¡å—è®­ç»ƒçš„æ¨¡åž‹ã€‚

ä½¿ç”¨æ–¹æ³•:
1. å‘½ä»¤è¡Œæ–¹å¼:
   python -m lm_eval --model hf-custom --model_args pretrained=/path/to/your/model,custom_modules_path=/path/to/custom/modules.py --tasks mmlu --output_path results

2. é€šè¿‡è¿™ä¸ªè„šæœ¬:
   python example_custom_evaluation.py
"""

import os
import sys
from pathlib import Path

# æ·»åŠ lm_evalåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from lm_eval import cli_evaluate
import argparse


def create_custom_args():
    """åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°å‚æ•°"""

    # è¿™é‡Œè®¾ç½®ä½ çš„æ¨¡åž‹è·¯å¾„
    MODEL_PATH = "/home/rtx3090/code_jiaxi/OwLore/output_models/my_finetuned_model/checkpoint-5/complete_model"

    # è‡ªå®šä¹‰æ¨¡å—è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æžœä¸ºNoneä¼šè‡ªåŠ¨æœç´¢ï¼‰
    CUSTOM_MODULES_PATH = None  # ä¾‹å¦‚: "/path/to/your/custom_modules.py"

    # åˆ›å»ºæ¨¡æ‹Ÿçš„å‘½ä»¤è¡Œå‚æ•°
    class Args:
        def __init__(self):
            # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡åž‹åŠ è½½å™¨
            self.model = "hf-custom"

            # æ¨¡åž‹å‚æ•°
            if CUSTOM_MODULES_PATH:
                self.model_args = {
                    "pretrained": MODEL_PATH,
                    "custom_modules_path": CUSTOM_MODULES_PATH,
                    "trust_remote_code": True,
                    "device": "cuda",  # æˆ– "cpu"
                }
            else:
                self.model_args = {
                    "pretrained": MODEL_PATH,
                    "trust_remote_code": True,
                    "device": "cuda",  # æˆ– "cpu"
                }

            # è¯„ä¼°ä»»åŠ¡
            self.tasks = "mmlu"  # ä½ å¯ä»¥æ”¹ä¸ºå…¶ä»–ä»»åŠ¡ï¼Œå¦‚ "hellaswag,arc_easy,arc_challenge"

            # è¾“å‡ºè®¾ç½®
            self.output_path = "custom_model_results"
            self.log_samples = True

            # Few-shot è®¾ç½®
            self.num_fewshot = 5

            # æ‰¹å¤„ç†è®¾ç½®
            self.batch_size = "auto"
            self.max_batch_size = 8

            # ç¼“å­˜è®¾ç½®
            self.cache_requests = "true"
            self.use_cache = None

            # å…¶ä»–è®¾ç½®
            self.device = "cuda"
            self.limit = None  # è®¾ä¸ºå°æ•°å­—å¦‚10è¿›è¡Œå¿«é€Ÿæµ‹è¯•
            self.samples = None
            self.check_integrity = False
            self.write_out = False
            self.system_instruction = None
            self.apply_chat_template = False
            self.fewshot_as_multiturn = False
            self.show_config = False
            self.include_path = None
            self.gen_kwargs = None
            self.verbosity = "DEBUG"  # ä½¿ç”¨DEBUGçº§åˆ«æŸ¥çœ‹è¯¦ç»†åŠ è½½è¿‡ç¨‹
            self.wandb_args = ""
            self.wandb_config_args = ""
            self.hf_hub_log_args = ""
            self.predict_only = False
            self.seed = [0, 1234, 1234, 1234]
            self.trust_remote_code = True
            self.confirm_run_unsafe_code = False
            self.metadata = None

    return Args()


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸš€ å¼€å§‹ä½¿ç”¨è‡ªå®šä¹‰æ¨¡åž‹åŠ è½½å™¨è¿›è¡Œè¯„ä¼°...")

    # åˆ›å»ºå‚æ•°
    args = create_custom_args()

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"ðŸ“ æ¨¡åž‹è·¯å¾„: {args.model_args['pretrained']}")
    print(f"ðŸ·ï¸  æ¨¡åž‹ç±»åž‹: {args.model}")
    print(f"ðŸ“Š è¯„ä¼°ä»»åŠ¡: {args.tasks}")
    print(f"ðŸ’¾ è¾“å‡ºè·¯å¾„: {args.output_path}")
    print(f"ðŸ”¢ Few-shotæ•°é‡: {args.num_fewshot}")
    print(f"âš¡ æ‰¹å¤„ç†å¤§å°: {args.batch_size}")

    try:
        # å¼€å§‹è¯„ä¼°
        cli_evaluate(args)
        print("âœ… è¯„ä¼°å®Œæˆ!")

    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def command_line_example():
    """æ˜¾ç¤ºå‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("ðŸ“ å‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹:")
    print("=" * 50)

    examples = [
        # åŸºæœ¬ç”¨æ³•
        """
# åŸºæœ¬ç”¨æ³•ï¼ˆè‡ªåŠ¨æœç´¢è‡ªå®šä¹‰æ¨¡å—ï¼‰:
python -m lm_eval \\
    --model hf-custom \\
    --model_args pretrained=/path/to/your/complete_model,trust_remote_code=True \\
    --tasks mmlu \\
    --output_path mmlu_results \\
    --num_fewshot 5 \\
    --batch_size auto \\
    --cache_requests true
        """,

        # æŒ‡å®šè‡ªå®šä¹‰æ¨¡å—è·¯å¾„
        """
# æŒ‡å®šè‡ªå®šä¹‰æ¨¡å—è·¯å¾„:
python -m lm_eval \\
    --model hf-custom \\
    --model_args pretrained=/path/to/your/complete_model,custom_modules_path=/path/to/custom_modules.py,trust_remote_code=True \\
    --tasks mmlu \\
    --output_path mmlu_results \\
    --num_fewshot 5 \\
    --batch_size auto \\
    --cache_requests true
        """,

        # å¤šä»»åŠ¡è¯„ä¼°
        """
# å¤šä»»åŠ¡è¯„ä¼°:
python -m lm_eval \\
    --model hf-custom \\
    --model_args pretrained=/path/to/your/complete_model,trust_remote_code=True \\
    --tasks hellaswag,arc_easy,arc_challenge,mmlu \\
    --output_path comprehensive_results \\
    --num_fewshot 5 \\
    --batch_size auto \\
    --log_samples \\
    --cache_requests true
        """
    ]

    for i, example in enumerate(examples, 1):
        print(f"\nç¤ºä¾‹ {i}:")
        print(example.strip())


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--examples":
        command_line_example()
    else:
        main()
        command_line_example()